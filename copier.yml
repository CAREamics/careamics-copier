# TODO general
# - check paths, record them as absolute paths

# TODO: Simple:
# - BMZ

# TODO Advanced:
# - Model checkpoint
# - Logging
# - structN2V

welcome_message:
  type: str
  help: |
    Welcome to the CAREamics experiment generator!

    This will set up your experiment, by building a configuration file and a python
    script for your CAREamics project.

    Before starting, make sure that you have your data organised in separate folders or
    files, and that you know the axes of your data.

    Press ENTER to continue.
  default: ""

mode:
  help: "Which mode would you like to use?"
  type: str
  default: simple
  choices:
    Simple - basic options: simple
    Advanced - loads of options: advanced

experiment_name:
  help: "What is the name of your CAREamics experiment? (no spaces, no special characters except underscores)"
  type: str
  default: my_experiment
  validator: >
    {% if not experiment_name.isidentifier() %}
      Experiment name must only contain letters, digits, or underscores, and not start with a digit.
    {% endif %}

#########################################
# Algorithm Selection
#########################################
algorithm_message:
  type: str
  help: |
    Let's turn to the Algorithm first. 

    Here are a list of available algorithms:

    - Noise2Void and N2V2 do not require ground-truth images.
    - Noise2Noise requires pairs of noisy images, of which some will be considered "ground-truth".
    - CARE requires pairs of noisy and clean images.

    Press ENTER to continue.
  default: ""

algorithm:
  help: "Which algorithm would you like to use?"
  type: str
  default: Noise2Void
  choices:
    Noise2Void - No ground-truth needed: n2v
    N2V2 - No ground-truth needed: n2v2
    Noise2Noise - Need pairs of noisy imagees: n2n
    CARE - Need pairs of noisy and clean images: care

# TODO add structN2V option

#########################################
# Data Selection
#########################################

data_message:
  type: str
  help: |
    Now let's talk about your data.

    You can choose between Zarr and Tiff formats, and can point to a folder containing
    your training data or to a file directly.

    Please note that if you choose CARE or Noise2Noise, you will need to provide a 
    path to ground truth or target data as well.

    Press ENTER to continue.
  default: ""

data_format:
  help: "What is the format of your data?"
  type: str
  default: tiff
  choices:
    zarr - Zarr files: zarr
    tiff - Tiff files: tiff

data_path:
  help: "Where is your input training data located? (e.g. /path/to/data)"
  type: str
  default: /path/to/data

# if N2N or CARE
target_path:
  help: "Where is your ground truth / target data located? (e.g. /path/to/ground_truth)"
  type: str
  default: /path/to/data
  when: "{{ algorithm == 'n2n' or algorithm == 'care' }}"
  validator: >
    {% if data_path == target_path %}
      Input and ground-truth / target paths must be different.
    {% endif %}

use_validation:
  help: "Do you want to use a separate validation set?"
  type: bool
  default: True

val_data_path:
  help: "Where is your validation data located? (e.g. /path/to/validation_data)"
  type: str
  default: /path/to/data
  when: "{{ use_validation }}"
  validator: >
    {% if data_path == val_data_path %}
      Training and validation paths must be different.
    {% endif %}

# if separate validation set and N2N or CARE
val_target_path:
  help: "Where is your validation ground truth / target data located? (e.g. /path/to/validation_ground_truth)"
  type: str
  default: /path/to/data
  when: "{{ use_validation and (algorithm == 'n2n' or algorithm == 'care') }}"
  validator: >
    {% if val_data_path == val_target_path %}
      Validation input and ground-truth paths must be different.
    {% endif %}

axes:
  help: "What are the axes of your data? (e.g. 'ZYX' or `ZYXC`, allowed values are 'STCZYX' in any order)"
  type: str
  default: YX

# if there is a channel dimension
n_input_channels:
  help: "How many input channels do you have? (e.g. 2)"
  type: int
  default: 1
  when: "{{ 'C' in axes }}"

# if there is a channel dimension and CARE or N2N
n_output_channels:
  help: "How many output channels do you have? (e.g. 1)"
  type: int
  default: 1
  when: "{{ 'C' in axes and (algorithm == 'n2n' or algorithm == 'care') }}"

# if there is a channel dimension
independent_channels:
  help: "Do you want to treat the channels independently?"
  type: bool
  default: True
  when: "{{ 'C' in axes }}"

########### Advanced Options ###########

augmentations_message:
  type: str
  help: |
    Now let's configure the augmentations.

    Press ENTER to continue.
  default: ""
  when: "{{ mode == 'advanced' }}"

flip_x:
  help: "Do you want to apply horizontal flips? (yes/no)"
  type: bool
  default: True
  when: "{{ mode == 'advanced' }}"

flip_y:
  help: "Do you want to apply vertical flips? (yes/no)"
  type: bool
  default: True
  when: "{{ mode == 'advanced' }}"

rot_90:
  help: "Do you want to apply 90Â° rotations? (yes/no)"
  type: bool
  default: True
  when: "{{ mode == 'advanced' }}"

#########################################
# Other parameters
#########################################

params_message:
  type: str
  help: |
    Almost there, just a few important parameters!

    Press ENTER to continue.
  default: ""

xy_patch_size:
  help: "What is the patch size in XY? (e.g. 64, 128, 256)"
  type: int
  default: 128

z_patch_size:
  help: "What is the patch size in Z? (e.g. 8, 16)"
  type: int
  default: 8
  when: "{{ 'Z' in axes }}"

batch_size:
  help: "What is the batch size? (e.g. 2, 8, 16, 32)"
  type: int
  default: 8

n_epochs:
  help: "How many epochs do you want to train for? (e.g. 20, 50)"
  type: int
  default: 50

#########################################
# Prediction
#########################################

prediction_message:
  type: str
  help: |
    Finally, let's set up the prediction parameters.

    Note that axes in the data are expected to be the same as in the training data.

    Press ENTER to continue.
  default: ""

should_predict:
  help: "Do you want to run a prediction after training?"
  type: bool
  default: True

prediction_path:
  help: "Where is the data you want to predict on located? (e.g. /path/to/prediction_data)"
  type: str
  default: /path/to/data
  when: "{{ should_predict }}"

should_tile:
  help: "Do you want to tile the prediction?"
  type: bool
  default: True
  when: "{{ should_predict }}"

xy_tile_size:
  help: "What is the XY tile size for prediction? (e.g. 128, 256)"
  type: int
  default: 256
  when: "{{ should_predict and should_tile }}"

z_tile_size:
  help: "What is the Z tile size for prediction? (e.g. 8, 16)"
  type: int
  default: 8
  when: "{{ 'Z' in axes and should_predict and should_tile }}"

xy_overlap:
  help: "What is the XY overlap for tiling? (e.g. 48, 64)"
  type: int
  default: 48
  when: "{{ should_predict and should_tile and mode == 'advanced' }}"

z_overlap:
  help: "What is the Z overlap for tiling? (e.g. 4, 8)"
  type: int
  default: 4
  when: "{{ 'Z' in axes and should_predict and should_tile and mode == 'advanced' }}"

output_path:
  help: "Where do you want to save the prediction results? (e.g. /path/to/output)"
  type: str
  default: /path/to/output
  when: "{{ should_predict }}"
  validator: >
    {% if prediction_path == output_path %}
      Prediction output path must be different from prediction input path.
    {% endif %}

##################### The end

# Final message
final_message:
  type: str
  help: |
    All done! 

    Your experiment is now set up. We will perform one last validation step to ensure that
    the configuration is correct, then the files will be generated.

    Press ENTER to finish.
  default: ""

#################### Exclude
_exclude:
  - "scripts/validate_config.py"
  - ".git"
  - ".gitignore"
  - "README.md"
  - "LICENSE"
  - "copier.yml"
  - "imgs"

##################### Validation
tasks:
  - "python {{ experiment_name }}/config.py"
  - "rm {{ experiment_name }}/config.py"
  - "black {{ experiment_name }}"
